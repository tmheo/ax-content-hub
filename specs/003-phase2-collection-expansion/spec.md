# Feature Specification: Phase 2 콘텐츠 수집 확장

**Feature Branch**: `003-phase2-collection-expansion`
**Created**: 2025-12-30
**Status**: Draft
**Input**: Phase 2 개발 계획 - RSS 외 다양한 소스 지원 및 품질 필터링 강화

## User Scenarios & Testing *(mandatory)*

### User Story 1 - RSS 없는 웹사이트 콘텐츠 수집 (Priority: P1)

운영자가 RSS 피드를 제공하지 않는 AI 블로그나 뉴스 사이트를 콘텐츠 소스로 등록하면, 시스템이 해당 웹사이트에서 자동으로 콘텐츠를 추출하여 수집한다. 웹사이트의 구조가 다양하므로 여러 추출 전략을 순차적으로 시도하여 최대한 많은 사이트를 지원한다.

**Why this priority**: RSS가 없는 사이트도 수집해야 콘텐츠 소스 풀을 확장할 수 있으며, 이는 다이제스트의 품질과 다양성을 높이는 핵심 기능이다.

**Independent Test**: WEB 타입 소스를 등록하고 수집을 실행하면 해당 웹사이트에서 콘텐츠가 추출되어 저장되는 것을 확인할 수 있다.

**Acceptance Scenarios**:

1. **Given** WEB 타입 소스가 등록되어 있고 CSS selector가 설정된 경우, **When** 수집이 실행되면, **Then** 해당 selector로 콘텐츠가 추출되어 저장된다.
2. **Given** WEB 타입 소스의 CSS selector가 작동하지 않는 경우, **When** 수집이 실행되면, **Then** 시스템이 자동으로 다음 추출 전략을 시도한다.
3. **Given** 동적 콘텐츠를 로드하는 웹사이트인 경우, **When** 수집이 실행되면, **Then** 시스템이 JavaScript 렌더링 후 콘텐츠를 추출한다.
4. **Given** 어떤 추출 전략으로도 콘텐츠를 찾지 못한 경우, **When** 수집이 완료되면, **Then** 실패 로그가 기록되고 빈 결과가 반환된다.

---

### User Story 2 - 자막 없는 YouTube 영상 수집 (Priority: P1)

기존 자막이 없는 YouTube 영상에서도 콘텐츠를 수집할 수 있도록, 음성 인식을 통해 자막을 생성한다. 이를 통해 자막을 제공하지 않는 채널의 영상도 다이제스트에 포함할 수 있다.

**Why this priority**: 많은 YouTube 채널이 자막을 제공하지 않으며, 이 기능 없이는 해당 콘텐츠를 수집할 수 없다.

**Independent Test**: 자막이 없는 YouTube 영상 URL을 포함한 소스에서 수집을 실행하면 음성 인식된 텍스트가 저장되는 것을 확인할 수 있다.

**Acceptance Scenarios**:

1. **Given** YouTube 소스의 영상에 기존 자막이 있는 경우, **When** 수집이 실행되면, **Then** 기존 자막을 사용하고 음성 인식은 수행하지 않는다.
2. **Given** YouTube 소스의 영상에 자막이 없고 영상 길이가 30분 이하인 경우, **When** 수집이 실행되면, **Then** 음성 인식을 통해 텍스트가 추출된다.
3. **Given** YouTube 소스의 영상에 자막이 없고 영상 길이가 30분 초과인 경우, **When** 수집이 실행되면, **Then** 해당 영상은 건너뛰고 로그에 기록된다.
4. **Given** 음성 인식 기능이 비활성화된 경우, **When** 자막 없는 영상 수집을 시도하면, **Then** 해당 영상은 건너뛰고 로그에 기록된다.

---

### User Story 3 - 중복 콘텐츠 필터링 (Priority: P2)

동일하거나 유사한 콘텐츠가 여러 소스에서 수집되었을 때, 다이제스트에서 중복을 제거하여 구독자에게 중복된 내용이 전달되지 않도록 한다.

**Why this priority**: 중복 콘텐츠는 사용자 경험을 저하시키지만, 수집 확장(P1) 이후에 의미가 있다.

**Independent Test**: 유사한 제목의 콘텐츠 여러 개를 수집한 후 필터링을 적용하면 중복이 제거되는 것을 확인할 수 있다.

**Acceptance Scenarios**:

1. **Given** 제목이 85% 이상 유사한 콘텐츠가 여러 개 있는 경우, **When** 품질 필터링이 적용되면, **Then** 가장 최신 콘텐츠만 유지되고 나머지는 제외된다.
2. **Given** 유사도 임계값이 0.9로 설정된 경우, **When** 80% 유사한 콘텐츠가 있으면, **Then** 두 콘텐츠 모두 유지된다.

---

### User Story 4 - 최신성 기반 필터링 (Priority: P2)

오래된 콘텐츠보다 최신 콘텐츠를 우선하여 다이제스트에 포함시켜, 구독자에게 시의적절한 정보를 제공한다.

**Why this priority**: 뉴스와 트렌드 콘텐츠의 가치는 시간이 지나면 감소하므로 최신성 필터링이 필요하다.

**Independent Test**: 다양한 날짜의 콘텐츠를 수집한 후 최신성 필터를 적용하면 기준일 이내의 콘텐츠만 남는 것을 확인할 수 있다.

**Acceptance Scenarios**:

1. **Given** 최신성 기준이 7일로 설정된 경우, **When** 필터링이 적용되면, **Then** 7일 이내에 수집된 콘텐츠만 포함된다.
2. **Given** 수집일이 없는 콘텐츠가 있는 경우, **When** 필터링이 적용되면, **Then** 해당 콘텐츠는 제외된다.

---

### User Story 5 - 콘텐츠 품질 검증 (Priority: P2)

본문이 너무 짧거나 제목이 없는 저품질 콘텐츠를 다이제스트에서 제외하여 구독자에게 의미 있는 콘텐츠만 전달한다.

**Why this priority**: 불완전하게 수집된 콘텐츠나 스팸성 콘텐츠를 걸러내야 다이제스트 품질이 유지된다.

**Independent Test**: 본문 길이가 다양한 콘텐츠를 수집한 후 품질 필터를 적용하면 기준 미달 콘텐츠가 제외되는 것을 확인할 수 있다.

**Acceptance Scenarios**:

1. **Given** 최소 본문 길이가 100자로 설정된 경우, **When** 50자 본문의 콘텐츠가 있으면, **Then** 해당 콘텐츠는 필터링에서 제외된다.
2. **Given** 제목 필수 옵션이 활성화된 경우, **When** 제목 없는 콘텐츠가 있으면, **Then** 해당 콘텐츠는 필터링에서 제외된다.

---

### Edge Cases

- 웹사이트가 봇 차단을 적용한 경우 어떻게 처리하는가? (User-Agent 로테이션, 적절한 요청 간격 유지)
- 웹 스크래핑 중 타임아웃이 발생한 경우 어떻게 처리하는가? (설정된 타임아웃 후 다음 전략 시도)
- YouTube API나 yt-dlp가 차단된 경우 어떻게 처리하는가? (실패 로그 기록, 해당 영상 건너뛰기)
- 음성 인식 처리 중 메모리 부족이 발생한 경우 어떻게 처리하는가? (경량 모델 사용, 영상 길이 제한 적용)
- 동일 콘텐츠가 다른 URL로 수집된 경우 어떻게 중복 판단하는가? (제목 유사도 기반)
- 수집 도중 웹사이트 구조가 변경된 경우 어떻게 대응하는가? (폴백 전략으로 자동 대응, 실패 시 로그 기록)

## Requirements *(mandatory)*

### Functional Requirements

#### Source 모델 확장
- **FR-001**: Source 모델은 WEB 타입을 지원해야 한다.
- **FR-002**: WEB 타입 소스는 CSS selector, 대기 selector, URL 패턴 설정을 포함할 수 있어야 한다.

#### 웹 스크래핑
- **FR-003**: 시스템은 정적 HTML에서 CSS selector로 콘텐츠를 추출할 수 있어야 한다.
- **FR-004**: 시스템은 JavaScript 렌더링이 필요한 동적 페이지에서 콘텐츠를 추출할 수 있어야 한다.
- **FR-005**: 시스템은 CSS selector가 작동하지 않을 때 페이지 구조 기반으로 본문을 추출할 수 있어야 한다.
- **FR-006**: 시스템은 페이지 내 링크 패턴을 분석하여 콘텐츠 URL을 식별할 수 있어야 한다.
- **FR-007**: 각 추출 전략 실패 시 다음 전략으로 자동 폴백되어야 한다.
- **FR-008**: 스크래핑 타임아웃은 설정 가능해야 하며 기본값은 30초이다.

#### YouTube STT 폴백
- **FR-009**: 시스템은 기존 YouTube 자막이 없을 때 음성 인식을 시도해야 한다.
- **FR-010**: 음성 인식은 설정으로 활성화/비활성화할 수 있어야 한다.
- **FR-011**: 음성 인식 대상 영상의 최대 길이는 설정 가능해야 하며 기본값은 30분이다.
- **FR-012**: 음성 인식 모델 크기는 설정 가능해야 하며 기본값은 base이다.
- **FR-013**: 영상에서 오디오를 추출할 수 있어야 한다.
- **FR-014**: 추출된 오디오에서 텍스트를 전사할 수 있어야 한다.
- **FR-015**: 임시 오디오 파일은 처리 완료 후 자동 삭제되어야 한다.

#### 품질 필터링 확장
- **FR-016**: 시스템은 제목 유사도 기반으로 중복 콘텐츠를 식별할 수 있어야 한다.
- **FR-017**: 중복 제거 시 유사도 임계값은 설정 가능해야 하며 기본값은 0.85이다.
- **FR-018**: 중복 제거 시 최신 콘텐츠가 우선 유지되어야 한다.
- **FR-019**: 시스템은 수집일 기준 N일 이내 콘텐츠만 필터링할 수 있어야 한다.
- **FR-020**: 시스템은 최소 본문 길이 기준으로 콘텐츠를 필터링할 수 있어야 한다.
- **FR-021**: 시스템은 제목 유무 기준으로 콘텐츠를 필터링할 수 있어야 한다.
- **FR-022**: 모든 품질 필터를 조합하여 적용할 수 있는 통합 메서드가 제공되어야 한다.

#### 콘텐츠 파이프라인 통합
- **FR-023**: ContentPipeline은 WEB 타입 소스를 웹 스크래핑 도구로 라우팅해야 한다.
- **FR-024**: 기존 YouTube 수집 로직에 STT 폴백이 통합되어야 한다.

### Key Entities

- **Source (확장)**: 콘텐츠 수집 대상을 정의하는 엔티티. WEB 타입이 추가되며, config 필드에 스크래핑 설정(selector, wait_for, url_pattern)을 저장한다.
- **ScrapedContent**: 웹 스크래핑 결과를 담는 값 객체. URL, 제목, 본문, 발행일, 추출 단계 정보를 포함한다.
- **WebScraperConfig**: 웹 스크래핑 설정을 담는 값 객체. CSS selector, URL 패턴, 대기 selector, 타임아웃 정보를 포함한다.

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: RSS가 없는 웹사이트 중 80% 이상에서 콘텐츠 수집에 성공한다.
- **SC-002**: 자막이 없는 YouTube 영상 중 90% 이상에서 음성 인식을 통해 텍스트 추출에 성공한다.
- **SC-003**: 중복 콘텐츠가 다이제스트에 포함되는 비율이 5% 미만으로 감소한다.
- **SC-004**: 수집 가능한 콘텐츠 소스 풀이 2배 이상 확대된다.
- **SC-005**: 품질 필터링 후 본문 100자 미만 또는 제목 없는 콘텐츠가 다이제스트에 포함되지 않는다.
- **SC-006**: 웹 스크래핑 단일 페이지 처리 시간이 60초 이내이다.
- **SC-007**: 30분 영상의 음성 인식 처리 시간이 10분 이내이다.

## Assumptions

- 웹사이트 소유자가 명시적으로 스크래핑을 금지하지 않은 사이트만 대상으로 한다.
- 음성 인식은 주로 한국어와 영어 콘텐츠를 대상으로 한다.
- Cloud Run 환경에서 최소 2GB 메모리가 제공된다고 가정한다.
- 외부 서비스(YouTube API, yt-dlp)의 가용성은 시스템 통제 범위 밖이다.
- 웹 스크래핑 요청 간격은 서버 부하 방지를 위해 적절히 조절된다.

## Constraints

- 음성 인식 처리는 서버 리소스를 많이 사용하므로 동시 처리 수를 제한해야 한다.
- 웹 스크래핑 시 대상 서버에 과도한 부하를 주지 않도록 요청 간격을 조절해야 한다.
- 저작권이 명확하지 않은 콘텐츠는 내부 처리용으로만 사용하고 재배포하지 않는다.
